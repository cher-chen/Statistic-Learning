{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "第一題 [myknn_regressor]\n",
    "首先，載入資料，並將X_train、Y_train、X_test、Y_test分別存入array。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# load data: X_train, Y_train, X_test, Y_test\n",
    "with (open(\"msd_data1.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            dataset = pickle.load(openfile)        \n",
    "        except EOFError:\n",
    "            break\n",
    "\n",
    "X_train = np.array(dataset['X_train']) # 90*5000 2D-array\n",
    "Y_train = np.array(dataset['Y_train']) # 5000 1D-array\n",
    "X_test = np.array(dataset['X_test']) # 90*3000 2D-array\n",
    "Y_test = np.array(dataset['Y_test']) # 3000 1D-array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myknn_regressor類別，含有以下function:\n",
    "    EuclidianDistance: 傳入兩一維陣列，計算兩個feature陣列的EuclidianDistance\n",
    "    remove_outliers: 移除不在[Q1−1.5IQR,Q3+1.5IQR]的離群值\n",
    "    fit: 傳入X_train, Y_train，做assign\n",
    "    predict: 傳入X_test，計算X_train與每一筆X_test的距離，取最近的K個，並利用這些feature所對應的Y_train之平均做為預測的y      \n",
    "其他function:\n",
    "    RMSE: 傳入兩陣列(預測值及實際值)，計算誤差\n",
    "    Standardize: 傳入陣列做標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# create class myknn_regressor\n",
    "class myknn_regressor:\n",
    "    \n",
    "    def __init__(self, k, method): \n",
    "        self.k = k \n",
    "        self.method = method\n",
    "        self.X_train = []\n",
    "        self.Y_train = []\n",
    "        \n",
    "    # fit the data \n",
    "    def fit(self, X_train, Y_train):\n",
    "        \n",
    "        self.X_train = X_train.copy()\n",
    "        self.Y_train = Y_train.copy()\n",
    "    \n",
    "    # calculate the Euclidian Distance\n",
    "    def EuclidianDistance(self, data1, data2, length):\n",
    "        return np.sqrt(np.sum((data1 - data2) ** 2))\n",
    "        \n",
    "    def remove_outliers(self, data):\n",
    "        \n",
    "        data_removeOutlier = []\n",
    "        IQR = np.quantile(data, 0.75) - np.quantile(data, 0.25)\n",
    "        lb = np.quantile(data, 0.25) - 1.5 * IQR\n",
    "        ub = np.quantile(data, 0.75) + 1.5 * IQR\n",
    "        for i in range(len(data)):\n",
    "            if data[i] >= lb and data[i] <= ub:\n",
    "                data_removeOutlier.append(data[i])\n",
    "                \n",
    "        return data_removeOutlier\n",
    "    \n",
    "        \n",
    "    # predicted y \n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        N_test = len(X_test)\n",
    "        pred_y = np.zeros(N_test)\n",
    "        \n",
    "        for s in range(N_test):\n",
    "            distList = []\n",
    "            for i in range(len(self.X_train)): \n",
    "                dist = self.EuclidianDistance(self.X_train[i], X_test[s], len(self.X_train[i]))\n",
    "                distList.append((self.Y_train[i], dist))     \n",
    "            distList.sort(key = lambda x: x[1])\n",
    "            neighbors_y = [distList[i][0] for i in range(self.k)]\n",
    "\n",
    "            if self.method == 'remove_outliers' and self.k >= 10:\n",
    "                neighbors_y = self.remove_outliers(neighbors_y)\n",
    "                pred_y[s] = sum(neighbors_y) / len(neighbors_y)\n",
    "                \n",
    "            else:\n",
    "                pred_y[s] = sum(neighbors_y) / len(neighbors_y)\n",
    "         \n",
    "        return pred_y\n",
    "\n",
    "# Root mean square error\n",
    "def RMSE(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())   \n",
    "\n",
    "# Standardize features\n",
    "def Standardize(data):\n",
    "    \n",
    "    N_feature = len(data[0])\n",
    "    N_data = len(data) \n",
    "    temp = np.ones((N_feature, N_data))\n",
    "    for n in range(N_data):\n",
    "        for f in range(N_feature):\n",
    "            temp[f][n] = data[n][f]\n",
    "    mean = [-1 for n in range(N_feature)]\n",
    "    std = [-1 for n in range(N_feature)]\n",
    "    for f in range(N_feature):\n",
    "        mean[f] = temp[f].mean()\n",
    "        std[f] = temp[f].std()\n",
    "    for n in range(N_data):\n",
    "        for f in range(N_feature):\n",
    "            data[n][f] = (data[n][f] - mean[f]) / std[f] \n",
    "\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_st = Standardize(X_train.copy())\n",
    "X_test_st = Standardize(X_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted y for equal_weight:\n",
      " [1992.9  1994.05 2000.05 1991.5  1992.8  1998.5  1987.1  1990.9  2001.8\n",
      " 2003.   2001.15 1998.65 1995.55 1997.2  1995.05 1997.35 1992.15 1999.1\n",
      " 2003.6  1995.75]\n",
      "RMSE_equal_weight= 10.292158827638316\n"
     ]
    }
   ],
   "source": [
    "myknn = myknn_regressor(20, \"equal_weight\")\n",
    "myknn.fit(X_train_st, Y_train)\n",
    "ypred = myknn.predict(X_test_st)\n",
    "print('predicted y for equal_weight:\\n',ypred[:20])\n",
    "print('RMSE_equal_weight=', RMSE(ypred, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted y for remove_outliers:\n",
      " [1992.9        1994.05       2000.05       1992.73684211 1992.8\n",
      " 2000.         1987.1        1990.9        2001.8        2003.94736842\n",
      " 2001.15       2000.94444444 1995.55       1997.2        1998.61111111\n",
      " 1997.35       1992.15       2004.23529412 2003.6        1995.75      ]\n",
      "RMSE_remove_outliers = 10.225720983625129\n"
     ]
    }
   ],
   "source": [
    "myknn2 = myknn_regressor(20, \"remove_outliers\")\n",
    "myknn2.fit(X_train_st, Y_train)\n",
    "ypred2 = myknn2.predict(X_test_st)\n",
    "print('predicted y for remove_outliers:\\n', ypred2[:20])\n",
    "print('RMSE_remove_outliers =', RMSE(ypred2, Y_test))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "第二題 [Tuning the Hyper-parameter]\n",
    "\n",
    "利用迴圈對每一個k值做以下處理:\n",
    "Case 1: 使用套件帶入標準化過的training data(即X_train_st)，並輸入標準化後的testing data(X_test_st)輸出預測值ypred，最後和實際值(Y_test)計算誤差(RMSE)，將RMSE存入list中\n",
    "Case 2: 使用套件帶入未標準化過的training data(即X_train)，並輸入未標準化後的testing data(X_test_st)輸出預測值ypred，最後和實際值(Y_test)計算誤差(RMSE)，將RMSE存入list中\n",
    "Case 3: 使用myknn_regressor，方法選擇remove_outliers，並輸入標準化後的testing data(X_test_st)輸出預測值ypred，最後和實際值(Y_test)計算誤差(RMSE)，將RMSE存入list中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    " \n",
    "    \n",
    "Klist = [1,2,3,4,5,10,15,20,25,30,35,40,45,50,55,60,80,100,120,140,160,180,200]\n",
    "\n",
    "RMSE_case1 = []\n",
    "RMSE_case2 = []\n",
    "RMSE_case3 = []\n",
    "\n",
    "for k in Klist:\n",
    "#   case1: knn with standardized feature\n",
    "    case1 = KNeighborsRegressor(n_neighbors = k)\n",
    "    case1.fit(X_train_st, Y_train)\n",
    "    ypred_case1 = case1.predict(X_test_st)\n",
    "    RMSE_case1.append(RMSE(ypred_case1, Y_test))\n",
    "\n",
    "#   case2: knn without standardized feature     \n",
    "    case2 = KNeighborsRegressor(n_neighbors = k)\n",
    "    case2.fit(X_train, Y_train)\n",
    "    ypred_case2 = case2.predict(X_test)\n",
    "    RMSE_case2.append(RMSE(ypred_case2, Y_test))   \n",
    "    \n",
    "#   case3: my knn\n",
    "    myknn = myknn_regressor(k, \"remove_outliers\")\n",
    "    myknn.fit(X_train_st, Y_train)\n",
    "    ypred_case3 = myknn.predict(X_test_st)\n",
    "    RMSE_case3.append(RMSE(ypred_case3, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_case3 = []\n",
    "for k in Klist:\n",
    "    myknn = myknn_regressor(k, \"remove_outliers\")\n",
    "    myknn.fit(X_train_st, Y_train)\n",
    "    ypred_case3 = myknn.predict(X_test_st)\n",
    "    RMSE_case3.append(RMSE(ypred_case3, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "將Case1、Case2、Case3的結果繪製成圖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.94019368588543, 12.097861381252473, 11.448255568232025, 11.043653909221652, 10.900440969673351, 10.46269085847422, 10.359457586258149, 10.292158827638316, 10.261870966511582, 10.257804039057469, 10.235202506063867, 10.209997388181186, 10.204546360311813, 10.228160003962914, 10.232596529500087, 10.242063661955804, 10.245796391589902, 10.260879617914505, 10.284962306823381, 10.299767106540788, 10.318954408812253, 10.347841640420786, 10.370087243686365]\n",
      "[14.923638966418345, 12.777499755429464, 12.075674967716129, 11.767805657810635, 11.466392632384432, 11.07746090040493, 10.888979137947995, 10.797788546734928, 10.79007301797969, 10.75026561256701, 10.717738719772289, 10.714437504678756, 10.698494013475852, 10.69110105960404, 10.682608734124413, 10.672535729098724, 10.662907517124493, 10.67701950452466, 10.683139638996407, 10.687017556442052, 10.691630026202155, 10.69071978380711, 10.698853374700175]\n",
      "[13.94019368588543, 12.097861381252473, 11.448255568232025, 11.043653909221652, 10.900440969673351, 10.51433799329082, 10.343823629898093, 10.225720983625129, 10.213345451143018, 10.188079193609305, 10.161597862384458, 10.095243787687673, 10.056682304105307, 10.089018275220825, 10.076818047624425, 10.089731397690318, 10.067742577227309, 10.063088284816118, 10.088531815151665, 10.10597373451231, 10.109055850913563, 10.14313493144064, 10.170153335037124]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# case1: knn with standardized feature - red\n",
    "# case2: knn without standardized feature - blue\n",
    "# case3: my knn - green\n",
    "\n",
    "plt.plot(Klist, RMSE_case1, 'r')\n",
    "plt.plot(Klist, RMSE_case2, 'b')\n",
    "plt.plot(Klist, RMSE_case3, 'g')\n",
    "plt.show()\n",
    "print(RMSE_case1)\n",
    "print(RMSE_case2)\n",
    "print(RMSE_case3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "由上圖可以發現，當k越大時，RMSE越小，即誤差越小，直到某個最低點又很緩慢的回升，呈現U型。\n",
    "先對feature做標準化的結果，RMSE明顯較位做標準化的還低，預測較準確。\n",
    "Case1的誤差最低點發生在k=45，Case2的誤差最低點發生在k=80，而Case3的誤差最低點發生在k=120。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
